import pandas as pd
import requests
import base64
import time
import math
import os
import json
import kagglehub
import google.generativeai as genai
from bs4 import BeautifulSoup
from tqdm import tqdm

# ==============================================================================
# CONFIGURATION GLOBALE & CLES API
# ==============================================================================
# Remplis tes cl√©s ici ou via des variables d'environnement
SPOTIFY_CLIENT_ID = os.getenv("SPOTIFY_CLIENT_ID", "TA_CLE_SPOTIFY_ID")
SPOTIFY_CLIENT_SECRET = os.getenv("SPOTIFY_CLIENT_SECRET", "TA_CLE_SPOTIFY_SECRET")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "TA_CLE_GEMINI_API")

# Noms de fichiers
FILE_SPOTIFY_JSON = 'dataset_final.json'         # Sortie partie 1
FILE_BILLBOARD_RAW = 'billboard_raw.csv'         # Interm√©diaire partie 2
FILE_BILLBOARD_ENRICHED = 'billboard_enriched.csv' # Sortie partie 2
FILE_FINAL_MERGED = 'GLOBAL_HIT_1980_2023_MMSS.csv' # Fichier FINAL

# Configuration Gemini
if GEMINI_API_KEY.startswith("TA_CLE"):
    print("‚ö†Ô∏è ATTENTION : Pense √† configurer ta cl√© GEMINI_API_KEY")
else:
    genai.configure(api_key=GEMINI_API_KEY)

MODEL_ROSTER = ['models/gemini-1.5-flash', 'models/gemini-1.5-pro']

# ==============================================================================
# PARTIE 1 : ETL SPOTIFY (Ton code original am√©lior√©)
# ==============================================================================

def get_region_from_code(code):
    """Transforme un code pays (2 lettres) en R√©gion globale."""
    if not code or len(code) != 2: return "Inconnu"
    code = code.upper()
    if code in ['US', 'CA', 'MX']: return "Am√©rique du Nord"
    if code in ['GB', 'FR', 'DE', 'SE', 'IT', 'ES', 'NL', 'NO', 'DK', 'IE', 'BE', 'CH']: return "Europe"
    if code in ['KR', 'JP', 'CN', 'IN', 'TW']: return "Asie"
    if code in ['BR', 'AR', 'CO', 'PR', 'CL']: return "Am√©rique Latine/ Am√©rique du Sud"
    if code in ['AU', 'NZ']: return "Oc√©anie"
    return "Reste du Monde"

def get_spotify_token():
    if SPOTIFY_CLIENT_ID.startswith("TA_CLE"):
        print("‚ùå Erreur : Cl√©s Spotify non configur√©es.")
        return None
        
    auth_url = "https://accounts.spotify.com/api/token"
    auth_string = f"{SPOTIFY_CLIENT_ID}:{SPOTIFY_CLIENT_SECRET}"
    auth_base64 = str(base64.b64encode(auth_string.encode("utf-8")), "utf-8")
    headers = {"Authorization": "Basic " + auth_base64, "Content-Type": "application/x-www-form-urlencoded"}
    data = {"grant_type": "client_credentials"}
    try:
        response = requests.post(auth_url, headers=headers, data=data, timeout=10)
        return response.json().get("access_token")
    except Exception as e:
        print(f"‚ùå Erreur Token Spotify : {e}")
        return None

def fetch_tracks_metadata(track_ids, token):
    ids_string = ",".join(track_ids)
    api_url = f"https://api.spotify.com/v1/tracks?ids={ids_string}"
    headers = {"Authorization": "Bearer " + token}
    metadata_map = {}
    try:
        response = requests.get(api_url, headers=headers, timeout=10)
        if response.status_code == 200:
            tracks_data = response.json().get('tracks', [])
            for track in tracks_data:
                if track and 'album' in track:
                    track_id = track['id']
                    release_date = track['album']['release_date']
                    year = release_date[:4] if release_date else None
                    images = track['album']['images']
                    image_url = images[0]['url'] if images else None
                    preview_url = track.get('preview_url')
                    external_ids = track.get('external_ids', {})
                    isrc = external_ids.get('isrc', '')
                    country_code = isrc[:2] if isrc and len(isrc) >= 2 else "XX"
                    region = get_region_from_code(country_code) if country_code != "XX" else "Inconnu"

                    metadata_map[track_id] = {
                        'year': year, 'image': image_url, 'preview': preview_url,
                        'country': country_code, 'region': region
                    }
        elif response.status_code == 429:
            time.sleep(5)
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur Batch Spotify : {e}")
    return metadata_map

def format_duration(ms):
    if pd.isna(ms): return "0:00"
    seconds = int((ms / 1000) % 60)
    minutes = int((ms / (1000 * 60)) % 60)
    return f"{minutes}:{seconds:02d}"

def run_spotify_etl():
    print("\n--- üü¢ 1. D√âMARRAGE ETL SPOTIFY (2000-2023) ---")
    if os.path.exists(FILE_SPOTIFY_JSON):
        print(f"‚úÖ Le fichier {FILE_SPOTIFY_JSON} existe d√©j√†. On passe.")
        return

    # Extract Kaggle
    print("üì• T√©l√©chargement Dataset Kaggle...")
    path = kagglehub.dataset_download("maharshipandya/-spotify-tracks-dataset")
    csv_file = [f for f in os.listdir(path) if f.endswith(".csv")][0]
    df = pd.read_csv(os.path.join(path, csv_file))

    # Filter
    df_hits = df[df['popularity'] >= 30].copy().drop_duplicates(subset=['track_id'])
    print(f"üìä {len(df_hits)} chansons √† traiter.")

    # Enrich API
    token = get_spotify_token()
    if not token: return

    track_ids = df_hits['track_id'].tolist()
    batch_size = 50
    full_metadata = {}

    print("üåç R√©cup√©ration m√©tadonn√©es API...")
    for i in tqdm(range(0, len(track_ids), batch_size)):
        batch = track_ids[i:i + batch_size]
        results = fetch_tracks_metadata(batch, token)
        full_metadata.update(results)
        time.sleep(0.2)

    # Transform
    def apply_enrichment(row):
        tid = row['track_id']
        if tid in full_metadata:
            d = full_metadata[tid]
            row['year'] = d['year']
            row['image'] = d['image']
            row['preview'] = d['preview']
            row['country_code'] = d['country']
            row['region'] = d['region']
        else:
            row['year'] = None
        row['duration_fmt'] = format_duration(row['duration_ms'])
        return row

    df_final = df_hits.apply(apply_enrichment, axis=1).dropna(subset=['year'])
    
    # Select Columns
    cols = ['track_name', 'artists', 'year', 'region', 'country_code', 
            'image', 'preview', 'duration_fmt', 'popularity', 
            'danceability', 'energy', 'tempo', 'track_genre']
    existing_cols = [c for c in cols if c in df_final.columns]
    
    # Save
    df_final[existing_cols].to_json(FILE_SPOTIFY_JSON, orient='records', indent=4)
    print(f"‚úÖ ETL Spotify termin√© : {FILE_SPOTIFY_JSON}")

# ==============================================================================
# PARTIE 2 : ETL BILLBOARD / GEMINI (1980-2000)
# ==============================================================================

def scrape_billboard(start_year, end_year):
    base_url = "https://en.wikipedia.org/wiki/Billboard_Year-End_Hot_100_singles_of_{}"
    headers = {'User-Agent': 'Mozilla/5.0'}
    all_songs = []

    print(f"üï∑Ô∏è Scraping Wikipedia de {start_year} √† {end_year}...")
    for year in range(start_year, end_year + 1):
        try:
            response = requests.get(base_url.format(year), headers=headers)
            soup = BeautifulSoup(response.text, 'html.parser')
            tables = soup.select('table.wikitable')
            target = next((t for t in tables if "Title" in t.text or "Song" in t.text), tables[0] if tables else None)
            
            if not target: continue

            for row in target.find_all('tr'):
                cols = row.find_all(['th', 'td'])
                if len(cols) < 2: continue
                
                track, artist = "Unknown", "Unknown"
                
                # Extraction basique
                texts = [c.get_text(strip=True).replace('"', '') for c in cols]
                # Logique simplifi√©e : souvent col 1 = titre, col 2 = artiste (si rang en col 0)
                if len(texts) >= 3:
                    if texts[0].isdigit() or not texts[0]: # C'est probablement le rang
                        track = texts[1]
                        artist = texts[2]
                    else:
                        track = texts[0]
                        artist = texts[1]
                
                if track not in ["Unknown", "Title", "Song"]:
                    all_songs.append({'track_name': track, 'artists': artist, 'year': year, 'region': 'US', 'country_code': 'US'})
        except Exception:
            pass
    
    return pd.DataFrame(all_songs)

def enrich_gemini(df_raw):
    print("ü§ñ Enrichissement via Gemini...")
    records = df_raw.to_dict('records')
    current_model = 0
    
    # Cr√©ation fichier vide si inexistant
    if not os.path.exists(FILE_BILLBOARD_ENRICHED):
        pd.DataFrame(columns=['track_name', 'artists', 'year', 'region', 'country_code', 'duration', 'tempo', 'track_genre', 'popularity']).to_csv(FILE_BILLBOARD_ENRICHED, index=False)
        start_idx = 0
    else:
        # Reprise
        start_idx = len(pd.read_csv(FILE_BILLBOARD_ENRICHED))
        print(f"üîÑ Reprise √† la ligne {start_idx}")

    batch_size = 30
    for i in tqdm(range(start_idx, len(records), batch_size)):
        batch = records[i:i+batch_size]
        success = False
        
        while not success:
            if current_model >= len(MODEL_ROSTER):
                print("üíÄ Quotas Gemini √©puis√©s.")
                return

            try:
                model = genai.GenerativeModel(MODEL_ROSTER[current_model])
                prompt = f"""
                DATA: {json.dumps(batch)}
                Pour chaque chanson, renvoie un JSON avec: track_name, artists, year, region, country_code (garder originaux),
                PLUS: duration (int secondes), tempo (int bpm), track_genre (string court), popularity (int 0-100).
                Format: Liste JSON valide uniquement.
                """
                response = model.generate_content(prompt)
                text = response.text.strip()
                if text.startswith("```"): text = text.split("\n", 1)[1].rsplit("\n", 1)[0]
                
                data = json.loads(text)
                df_batch = pd.DataFrame(data)
                
                # Colonnes manquantes
                for c in ['duration', 'tempo', 'track_genre', 'popularity']:
                    if c not in df_batch.columns: df_batch[c] = None

                df_batch.to_csv(FILE_BILLBOARD_ENRICHED, mode='a', header=False, index=False)
                success = True
                time.sleep(1)
            except Exception as e:
                if "429" in str(e):
                    print("‚ö†Ô∏è Changement de mod√®le Gemini...")
                    current_model += 1
                else:
                    print(f"‚ö†Ô∏è Erreur batch: {e}")
                    success = True # On skip pour pas bloquer

def run_billboard_etl():
    print("\n--- üü° 2. D√âMARRAGE ETL BILLBOARD (1980-2000) ---")
    
    # 1. Scrape
    if not os.path.exists(FILE_BILLBOARD_RAW):
        df = scrape_billboard(1980, 2005) # On prend large
        df.to_csv(FILE_BILLBOARD_RAW, index=False)
    else:
        df = pd.read_csv(FILE_BILLBOARD_RAW)
    
    # 2. Enrich
    if os.path.exists(FILE_BILLBOARD_ENRICHED) and len(pd.read_csv(FILE_BILLBOARD_ENRICHED)) >= len(df):
        print("‚úÖ Enrichissement d√©j√† termin√©.")
    else:
        enrich_gemini(df)

# ==============================================================================
# PARTIE 3 : FUSION FINALE
# ==============================================================================

def seconds_to_mm_ss(val):
    try:
        if pd.isna(val): return None
        seconds = int(float(val))
        return f"{seconds // 60}:{seconds % 60:02d}"
    except: return None

def run_fusion():
    print("\n--- üîµ 3. D√âMARRAGE FUSION FINALE ---")
    
    # Load Spotify
    if not os.path.exists(FILE_SPOTIFY_JSON): return print("‚ùå Manque fichier Spotify")
    df_spotify = pd.read_json(FILE_SPOTIFY_JSON)
    df_spotify['year'] = pd.to_numeric(df_spotify['year'], errors='coerce')
    df_spotify = df_spotify[df_spotify['year'] >= 2000] # On garde le r√©cent
    if 'duration_fmt' in df_spotify.columns:
        df_spotify = df_spotify.rename(columns={'duration_fmt': 'duration'})

    # Load Billboard
    if not os.path.exists(FILE_BILLBOARD_ENRICHED): return print("‚ùå Manque fichier Billboard")
    df_billboard = pd.read_csv(FILE_BILLBOARD_ENRICHED)
    df_billboard = df_billboard[df_billboard['year'] < 2000] # On garde le vieux
    df_billboard['duration'] = df_billboard['duration'].apply(seconds_to_mm_ss)

    # Merge
    cols = ['track_name', 'artists', 'year', 'duration', 'tempo', 'track_genre', 'popularity', 'region', 'country_code']
    
    # S√©curisation colonnes
    for df in [df_spotify, df_billboard]:
        for c in cols:
            if c not in df.columns: df[c] = None

    df_final = pd.concat([df_billboard[cols], df_spotify[cols]], ignore_index=True)
    df_final = df_final.sort_values(by='year')
    
    df_final.to_csv(FILE_FINAL_MERGED, index=False)
    print(f"üéâ FUSION TERMIN√âE ! Fichier g√©n√©r√© : {FILE_FINAL_MERGED}")
    print(f"üìä Total lignes : {len(df_final)}")

# ==============================================================================
# MAIN EXECUTION
# ==============================================================================
if __name__ == "__main__":
    run_spotify_etl()
    run_billboard_etl()
    run_fusion()